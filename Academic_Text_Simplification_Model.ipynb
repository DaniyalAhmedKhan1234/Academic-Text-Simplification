{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f41788",
   "metadata": {},
   "source": [
    "# Academic Text Simplification Model\n",
    "\n",
    "This notebook contains a model designed to simplify academic text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ArmandDS/lexical_simplification_bert/blob/master/Lexical_Simplification_with_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2Jy5bVTq9OQ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgwnAPBHq7yN"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2eRTpjC2nX-"
   },
   "source": [
    "#Text Simplification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpM2SSum2qUr"
   },
   "source": [
    "###Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4vIptzMAqmSR",
    "outputId": "c8d6b5b4-c75a-48fc-85a9-a1bbca30b4ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textstat in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
      "Requirement already satisfied: pyphen in /usr/local/lib/python3.7/dist-packages (from textstat) (0.10.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 287,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "!pip install textstat\n",
    "!pip install tqdm\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "# Get the interactive Tools for Matplotlib\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from nltk import ngrams\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, RepeatVector,Flatten, TimeDistributed, Input,Bidirectional,LocallyConnected1D,Conv1D,GlobalAveragePooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Embedding, LSTM ,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import optimizers\n",
    "# from tensorflow.keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# import tensorflow.keras.utils.to_categorical as to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import textstat\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsRawIZ82tzn"
   },
   "source": [
    "###Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDYG2--TizTk",
    "outputId": "03b5797f-8e19-492a-accc-630086ef543e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "path = \"/content/drive/My Drive\"\n",
    "X_Test = pd.read_csv(path + \"/X_Test.txt\", sep='\\n')\n",
    "X_Train = pd.read_csv(path + \"/X_Train.txt\", sep='\\n')\n",
    "Y_Test = pd.read_csv(path + \"/Y_Test.txt\", sep='\\n')\n",
    "Y_Train = pd.read_csv(path + \"/Y_Train.txt\", sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umOLZgBrjFRp"
   },
   "outputs": [],
   "source": [
    "# Perform operations\n",
    "X_Test = list(X_Test[\"X_Test\"])\n",
    "X_Train = list(X_Train[\"X_Train\"])\n",
    "Y_Test = list(Y_Test[\"Y_Test\"])\n",
    "Y_Train = list(Y_Train[\"Y_Train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voFdvNpGjMIA"
   },
   "outputs": [],
   "source": [
    "# Perform operations\n",
    "X_Train = X_Train[0:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqVjSfhO2x0o"
   },
   "source": [
    "###Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7W4pFRXDjYZ3"
   },
   "outputs": [],
   "source": [
    "# Perform operations\n",
    "def preprocess(X):\n",
    "  for i in range(len(X)):\n",
    "    X[i] = X[i].replace(\"'\",'')\n",
    "    X[i] = X[i].replace(\".\",'')\n",
    "\n",
    "    X[i] = X[i]\n",
    "  return X\n",
    "X_Train = preprocess(X_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bg9iGi5VwVhH"
   },
   "outputs": [],
   "source": [
    "# Perform operations\n",
    "def getVocabulary(data_X):\n",
    "    #list of sentences\n",
    "    joined_data_X = \" \".join(data_X)\n",
    "    vocab_list = list(set(joined_data_X.split(\" \")))\n",
    "    return vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfFPqnJfwYVJ",
    "outputId": "4e85af14-2a91-414c-e42c-f274b0b662d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Vocab from Train Data: 45962\n"
     ]
    }
   ],
   "source": [
    "# Perform operations\n",
    "Train_Vocab = getVocabulary(X_Train)\n",
    "Print('Length of Vocab from Train Data:',len(Train_Vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44UaYVUa27tA"
   },
   "source": [
    "###Complexity Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3OfE50VwZeT"
   },
   "outputs": [],
   "source": [
    "# Perform operations\n",
    "def mapComplexity(words):\n",
    "  Complexity_Score = {}\n",
    "  for word in tqdm(words):\n",
    "    if textstat.difficult_words(word) == 1:\n",
    "      Complexity_Score[word]=1\n",
    "    else:\n",
    "      Complexity_Score[word]=0\n",
    "  return Complexity_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FnUo0i0BwkoS",
    "outputId": "a5bc4d4f-0166-4708-b8f8-c68a6816994e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45962/45962 [01:02<00:00, 729.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform operations\n",
    "Train_Complexity_Score = mapComplexity(Train_Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVYx5gVerXCF",
    "outputId": "dae1e4f1-be3b-41a1-e71b-4a253c585c97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "# Perform operations\n",
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GW3A-u9c3B_m"
   },
   "source": [
    "###Building the BIRT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dtRGV68II0q",
    "outputId": "ebb30393-41b3-4863-891e-efc337dc41fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=1024, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 290,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "bert_model = 'bert-large-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "model = BertForMaskedLM.from_pretrained(bert_model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCjuu21qNDk2"
   },
   "source": [
    "To compute the **Zipf values**, we use the library **wordfreq**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIx9Fo5nLrlE",
    "outputId": "29cc212b-8252-41ac-f3ba-91926c49599d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordfreq in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (1.0.2)\n",
      "Requirement already satisfied: regex>=2020.04.04 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (2021.4.4)\n",
      "Requirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Perform operations\n",
    "!pip install wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7l-H8loKIgMF"
   },
   "outputs": [],
   "source": [
    "# Perform operations\n",
    "def generate_candidates(sentence, complex_index):\n",
    "  candidates = []\n",
    "  input_list = sentence.split()\n",
    "  for i in range(len(input_list)):\n",
    "    tag = pos_tag([input_list[i]])[0][1]\n",
    "    zipfscore = (zipf_frequency(input_list[i], 'en'))\n",
    "    replace = False\n",
    "    if complex_index[i] > 0 and tag in  ['NNS', 'NN', 'VBP', 'RB', 'VBG','VBD' ]:\n",
    "      replace = True\n",
    "    if zipfscore < 3.1:\n",
    "      replace = True\n",
    "    if replace:\n",
    "      tagged = '[CLS]'+ sentence.replace(input_list[i], '[MASK]') + ' [SEP] ' + sentence + ' [SEP] '\n",
    "      counter = 0\n",
    "      m = 0\n",
    "      for tok in tokenizer.tokenize(tagged):\n",
    "        if tok == '[MASK]':\n",
    "          m = counter\n",
    "          counter += 1\n",
    "        counter += 1\n",
    "      with torch.no_grad():\n",
    "          network = model(torch.tensor([tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tagged))]), token_type_ids=torch.tensor([[0 for i in range(len(tokenizer.tokenize(tagged)))]]))\n",
    "          results = network[0][0][m]\n",
    "      tokens = tokenizer.convert_ids_to_tokens(list(torch.argsort(results, descending=True)[:10]))\n",
    "      candidates.append((input_list[i],tokens))\n",
    "  return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRVA2g4rPiKY",
    "outputId": "20eb4a74-5119-48cd-f293-6320650e8d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textstat in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
      "Requirement already satisfied: pyphen in /usr/local/lib/python3.7/dist-packages (from textstat) (0.10.0)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "!pip install textstat\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RFl_PPkLOGyG",
    "outputId": "60885b5e-2b9d-433b-f551-fc86abfee32d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:01<02:57,  1.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('preseason', ['preseason', 'practice', 'playoff', 'reserve', 'training', 'rookie', 'preliminary', 'draft', 'league', 'september']), (',', [',', 'kurt', 'jack', 'and', 'pop', ';', 'john', '.', 'tom', ':']), ('tentative', [\"'\", 'temporary', 'interim', 'tentative', '′', 'second', 'starting', 'permanent', 'reserve', 'first'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 2/100 [00:03<02:40,  1.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('twentieth', ['twentieth', 'seventh', 'sixth', 'sixteenth', 'second', 'eighth', 'fifteenth', 'seventeenth', 'tenth', 'eighteenth']), ('Entertainment', ['.', 'entertainment', ';', '!', 'corporation', 'authority', 'championship', 'championships', 'federation', 'company'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 3/100 [00:04<02:41,  1.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Janko', ['jan', 'ivan', 'anton', 'ivo', 'peter', 'marko', 'martin', 'erik', 'milan', 'gregor']), ('Prunk', ['novak', 'lang', 'martin', 'muller', 'gross', 'pop', 'gregor', 'jug', 'berger', 'richter']), ('Slovenian', ['slovenian', 'slovene', 'slovenia', 'norwegian', 'yugoslav', 'slovak', 'croatian', 'polish', 'ljubljana', 'montenegrin']), ('historian', ['historian', 'scholar', 'professor', 'author', 'writer', 'teacher', 'academic', 'specialist', 'researcher', 'philosopher'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 4/100 [00:16<07:31,  4.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('balalaika', ['.', 'the', ')', '-', ';', \"'\", ',', 'of', 'a', ':']), ('``', ['in', 'russian', 'by', 'the', 'for', 'a', '`', 'into', 'with', 'from']), ('guitar', ['players', 'guitars', 'guitarists', 'playing', 'guitar', 'player', 'on', 'solos', 'guitarist', '##s']), (',', ['although', 'however', 'though', 'whilst', 'but', 'despite', 'albeit', 'while', 'whereas', ',']), ('guitar', ['players', 'guitars', 'guitarists', 'playing', 'guitar', 'player', 'on', 'solos', 'guitarist', '##s']), ('players', ['players', 'musicians', 'playing', 'player', 'users', 'guitarists', 'fans', 'enthusiasts', 'students', 'listeners']), (',', ['although', 'however', 'though', 'whilst', 'but', 'despite', 'albeit', 'while', 'whereas', ',']), ('balalaika', ['.', 'the', ')', '-', ';', \"'\", ',', 'of', 'a', ':']), ('purists', ['players', 'enthusiasts', 'fans', 'musicians', 'guitarists', 'makers', 'experts', 'critics', 'collectors', 'proponents']), ('tuning', ['.', ';', '!', '?', '...', ',', ':', '|', '-', '।'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 5/100 [00:23<08:41,  5.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', ['marking', 'marked', 'mark', 'during', 'breaking', 'signalling', 'commemorating', 'announcing', 'commemoration', 'signaling']), ('occurred', ['occurred', 'occurs', 'occur', 'happened', 'occurring', 'resulted', 'began', 'commenced', 'occurrence', 'proceeded']), (',', ['marking', 'marked', 'mark', 'during', 'breaking', 'signalling', 'commemorating', 'announcing', 'commemoration', 'signaling']), ('marking', ['marking', 'marked', 'signalling', 'marks', 'mark', 'commemorating', 'representing', 'signaling', 'indicating', 'marker']), ('Depression', ['the', ',', 'of', 'a', '.', 'and', 'as', 'in', 'to', 'that']), ('subsequent', ['subsequent', 'resultant', 'the', 'subsequently', 'resulting', 'ensuing', 'previous', 'following', 'concurrent', 'accompanying']), ('Depression', ['the', ',', 'of', 'a', '.', 'and', 'as', 'in', 'to', 'that'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 6/100 [00:26<07:22,  4.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dolignon', ['bois', 'croix', 'fontaine', 'mont', 'pont', 'chateau', 'fay', 'belmont', 'rouge', 'nes']), ('commune', ['commune', 'communes', 'department', 'village', 'canton', 'municipality', 'laval', 'town', 'prefecture', 'somme']), ('Aisne', ['somme', 'nord', 'normandy', 'seine', 'marne', 'sable', 'ain', 'var', 'bray', 'cher']), ('department', ['department', 'departments', 'region', 'district', 'drainage', 'arrondissement', 'valley', 'dept', 'river', 'mountains']), ('Picardie', ['normandy', 'brittany', 'nord', 'burgundy', 'alsace', 'lorraine', 'navarre', 'aquitaine', 'france', 'maine'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 7/100 [00:30<06:56,  4.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('congruent', ['prime', 'rational', 'positive', 'natural', 'composite', 'perfect', 'odd', 'irrational', 'real', 'negative']), ('conjectured', ['conjecture', 'stated', 'known', 'claimed', 'presumed', 'considered', 'predicted', 'supposed', 'suppose', 'determined']), ('aliquot', ['exponential', 'infinite', 'incidence', 'induction', 'integer', 'evolutionary', 'ordered', 'joshua', 'apple', 'abc'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 8/100 [00:33<06:06,  3.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('reputation', ['reputation', 'nickname', 'name', 'fame', 'notoriety', 'tradition', 'reputed', 'popularity', 'record', 'conviction']), (',', [',', 'in', 'for', 'by', 'and', ';', 'while', 'of', '.', '-']), ('decisions', ['decisions', 'decision', 'choices', 'statements', 'changes', 'judgments', 'plans', 'mistakes', 'actions', 'calculations']), ('advantage', ['advantage', 'advantages', 'account', 'disadvantage', 'care', 'control', 'effect', 'charge', 'exploited', 'offense']), ('confusion', ['.', ';', '!', '?', '...', '|', ',', ':', '।', '-'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 9/100 [00:37<05:53,  3.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('controller', ['controller', 'manager', 'operator', 'director', 'ceo', 'owner', 'supervisor', 'president', 'dj', 'head']), ('Danny', ['danny', 'daniel', 'dan', 'jack', 'mike', 'marc', 'calvin', 'michael', 'martin', 'benny']), ('Cohen', ['cohen', 'goldberg', 'davies', 'leonard', 'friedman', 'jewish', 'lang', 'hirsch', 'levine', 'kelly']), (',', [',', '.', ';', '-', 'and', '...', ':', '(', ')', '##s']), ('Scheduling', ['scheduling', 'programming', 'schedule', 'schedules', 'booking', 'timing', 'operations', 'production', 'budget', 'planning']), ('McGolpin', ['.', ';', '!', '...', 'davis', 'johnson', '?', 'wilson', 'cohen', 'harris'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 10/100 [00:37<04:22,  2.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('quotation', ['question', 'line', 'quote', 'title', 'figure', 'text', 'tab', 'number', 'data', 'check'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 11/100 [00:44<05:46,  3.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Kansas', ['kansas', 'chicago', 'alabama', 'journey', 'texas', 'springfield', 'nebraska', 'cream', 'heart', 'oklahoma']), (',', [',', '.', 'and', ';', '-', 'along', '...', 'associated', 'also', 'primarily']), ('singles', ['singles', 'songs', 'records', 'single', 'albums', 'tracks', 'hits', 'recordings', 'releases', 'films']), ('``', ['dust', 'wind', 'sand', 'smoke', 'dirt', 'light', 'stir', 'snow', 'chill', 'something']), ('Wayward', ['my', 'westward', 'beloved', 'prairie', 'runaway', 'wandering', '##away', 'dear', 'young', 'native']), ('``', ['dust', 'wind', 'sand', 'smoke', 'dirt', 'light', 'stir', 'snow', 'chill', 'something'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 12/100 [00:45<04:30,  3.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('campus', ['public', 'regional', 'private', 'state', 'research', 'comprehensive', 'community', 'city', 'campus', 'technical']), ('university', ['university', 'college', 'institution', 'school', 'institute', 'universities', 'campus', 'city', 'polytechnic', 'academy']), ('aspects', ['.', ';', 'dresden', '?', '!', '|', 'germany', 'berlin', 'bremen', '##en'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 13/100 [00:45<03:16,  2.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Lenoir', ['.', ';', '?', '|', '...', '!', ':', ',', 'here', 'katy'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 14/100 [01:00<08:33,  5.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', [',', '.', 'the', '-', 'of', 'a', 'and', 'that', 'to', 'as']), (',', [',', '.', 'the', '-', 'of', 'a', 'and', 'that', 'to', 'as']), ('CNET', ['billboard', 'forbes', 'variety', 'mtv', 'cnn', 'time', 'youtube', 'reuters', 'yahoo', 'complex']), ('reported', ['reported', 'report', 'reports', 'noted', 'reporting', 'commented', 'wrote', 'estimated', 'announced', 'stated']), ('possibly', ['possibly', 'likely', 'potentially', 'perhaps', 'probably', 'previously', 'not', 'recently', 'definitely', 'reportedly']), ('WMG', ['the', 'their', 'its', 'these', 'such', 'new', 'those', 'both', 'some', 'similar']), ('appearing', ['appearing', 'arriving', 'appearance', 'appear', 'appearances', 'emerging', 'appeared', 'featuring', 'showing', 'appears']), (',', [',', '.', 'the', '-', 'of', 'a', 'and', 'that', 'to', 'as'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 15/100 [01:00<06:07,  4.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('areas', ['areas', 'zones', 'regions', 'places', 'sites', 'locations', 'spots', 'environments', 'area', 'zone'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 16/100 [01:07<07:02,  5.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Alfonso', ['.', 'the', ')', ',', '-', \"'\", ';', 'a', 'of', '##i']), ('Pérez', ['perez', 'fernandez', 'garcia', 'rodriguez', 'lopez', 'rivera', 'martinez', 'gonzalez', 'gomez', 'alvarez']), ('Muñoz', ['munoz', 'perez', 'fernandez', 'jimenez', 'garcia', 'martinez', 'rodriguez', 'rivera', 'lopez', 'diaz']), (',', ['.', 'the', ')', 'a', ';', ',', '-', \"'\", 'of', '##i']), ('usually', ['usually', 'commonly', 'often', 'sometimes', 'always', 'generally', 'normally', 'also', 'typically', 'rarely']), ('Alfonso', ['.', 'the', ')', ',', '-', \"'\", ';', 'a', 'of', '##i']), (',', ['.', 'the', ')', 'a', ';', ',', '-', \"'\", 'of', '##i']), ('footballer', ['footballer', 'football', 'player', 'cyclist', 'footballers', 'politician', 'manager', 'defender', 'referee', 'midfielder']), (',', ['.', 'the', ')', 'a', ';', ',', '-', \"'\", 'of', '##i']), ('striker', ['striker', 'forward', 'midfielder', 'defender', 'midfield', 'player', 'centre', 'fullback', 'central', 'winger']), ('position', ['.', ';', '...', '?', ',', '!', ':', '|', 'and', ')'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 17/100 [01:12<06:49,  4.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('countries', ['countries', 'places', 'nations', 'jurisdictions', 'country', 'lands', 'areas', 'governments', 'states', 'regions']), (',', [',', 'such', 'these', 'the', 'notable', 'historical', 'historic', 'some', 'many', '.']), ('landmarks', ['landmarks', 'they', 'shrines', 'these', 'structures', 'monuments', 'landmark', 'icons', 'buildings', 'relics']), ('``', ['`', \"'\", ':', 'as', '′', '*', 'national', '#', 'the', 'a']), ('historic', ['historic', 'historical', 'ancient', 'modern', 'architectural', 'shrine', 'heritage', 'original', 'memorial', 'religious']), ('include', ['include', 'includes', 'are', 'included', 'including', 'vary', 'list', 'note', 'cite', 'contain']), (':', [';', '.', ':', '?', '!', '|', '...', ',', '-', '[UNK]'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 18/100 [01:13<05:11,  3.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('stilt', ['pit', 'stone', 'round', 'timber', 'terrace', 'circular', 'wooden', 'roman', 'flat', 'croft']), ('houses', ['houses', 'dwellings', '##houses', 'house', 'huts', 'homes', 'cottages', 'buildings', 'structures', 'housing'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 19/100 [01:16<04:54,  3.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('comprises', ['comprises', 'includes', 'comprising', 'consists', 'constitutes', 'comprise', 'encompasses', 'contains', 'organizes', 'incorporates']), ('churches', ['churches', 'church', 'fellowships', 'congregations', 'groups', 'parties', 'governments', 'protestants', 'christians', 'communities']), (',', ['nine', 'eight', '9', 'four', 'ten', 'two', 'six', 'seven', 'three', '14']), (',', ['nine', 'eight', '9', 'four', 'ten', 'two', 'six', 'seven', 'three', '14']), ('Lutheran', ['lutheran', 'catholic', 'evangelical', 'protestant', 'presbyterian', 'catholics', 'methodist', 'synod', 'orthodox', 'protestants'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 20/100 [01:54<18:44, 14.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Originally', ['originally', 'original', 'initial', 'initially', 'first', 'earlier', 'previously', 'originated', 'originating', 'officially']), ('setup', ['created', 'setup', 'established', 'formed', 'establishment', 'conceived', 'creation', 'activation', 'constituted', 'originated']), ('Traffic', ['when', 'was', 'upon', 'after', 'on', 'then', 'during', 'in', 'to', 'with']), ('Control', ['services', 'service', 'units', 'sections', 'control', 'components', 'wings', 'systems', 'forces', 'controllers']), ('Services', ['when', 'upon', 'was', 'after', 'on', 'during', 'then', 'in', 'by', 'until']), (',', ['the', 'da', 'new', 'it', 'i', 'he', 'this', 'there', 'la', 'that']), ('bringing', ['bringing', 'brought', 'coming', 'bring', 'brings', 'drawing', 'putting', 'taking', 'grouping', 'gathering']), ('responsibility', ['for', 'of', 'over', 'and', 'with', 'after', 'to', 'control', 'in', 'by']), ('existing', ['existing', 'established', 'current', 'developing', '.', 'various', \"'\", 'growing', 'emerging', '##stituting']), ('Traffic', ['when', 'was', 'upon', 'after', 'on', 'then', 'during', 'in', 'to', 'with']), ('Control', ['services', 'service', 'units', 'sections', 'control', 'components', 'wings', 'systems', 'forces', 'controllers']), ('services', ['services', 'systems', 'components', 'service', 'functions', 'operations', 'facilities', 'sections', 'units', 'forces']), (',', ['the', 'da', 'new', 'it', 'i', 'he', 'this', 'there', 'la', 'that']), ('organization', ['organization', 'organisation', 'entity', 'organizations', 'organizational', 'agency', 'program', 'designation', 'group', 'system']), ('Traffic', ['when', 'was', 'upon', 'after', 'on', 'then', 'during', 'in', 'to', 'with']), ('Services', ['when', 'upon', 'was', 'after', 'on', 'during', 'then', 'in', 'by', 'until']), ('responsibility', ['for', 'of', 'over', 'and', 'with', 'after', 'to', 'control', 'in', 'by']), ('sponsoring', ['sponsoring', 'funding', 'sponsorship', 'hosting', 'sponsor', 'sponsors', 'overseeing', 'servicing', 'programming', 'launching']), ('traffic', ['traffic', 'navigation', 'transport', 'customs', 'control', 'toll', 'ferry', 'route', 'flight', '-']), ('component', ['component', 'components', 'portion', 'element', 'program', 'section', 'unit', 'contribution', 'feature', 'part']), ('newly', ['newly', 'recently', 'new', 'freshly', 'newer', 'subsequently', 'previously', 'similarly', 'later', 'now']), ('Civil', ['civil', 'general', 'civilian', 'joint', 'commercial', 'defence', 'motor', 'air', 'military', 'public']), ('Aviation', ['aviation', 'aircraft', 'air', 'airspace', 'airports', 'aeronautics', 'airport', 'aeronautical', 'transport', 'flying']), ('Authority', ['authority', 'authorities', 'agency', 'board', 'council', 'association', 'organisation', 'body', 'administration', 'office'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 21/100 [02:11<19:25, 14.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('egress', ['entrance', 'entry', 'approach', 'passage', 'exit', 'access', 'route', 'outlet', 'opening', 'channel']), ('easily', ['easily', 'easy', 'lightly', 'heavily', 'often', 'effortlessly', 'usually', 'readily', 'almost', 'effectively']), ('blockaded', ['blocked', 'blockade', 'guarded', 'controlled', 'barred', 'defended', 'closed', 'constrained', 'restricted', '##ricted']), ('consisting', ['consisting', 'composing', 'comprising', 'consists', 'consist', 'forming', 'composed', 'because', 'concentrating', 'characteristic']), ('marshy', ['sandy', 'fertile', 'flat', 'muddy', 'shallow', 'flooded', 'dry', 'rich', 'delta', 'broad']), ('Shatt', ['wadi', 'ain', 'tell', 'tel', 'umm', 'river', 'dar', 'ras', 'abd', 'tal']), (',', ['the', ',', '.', 'of', '-', 'and', 'a', 'to', 'as', 'in']), ('waters', ['waters', 'water', 'fluids', '##water', 'liquids', 'waterways', 'flows', 'freshwater', 'streams', 'rivers']), ('Euphrates', ['indus', 'jordan', 'nile', 'caspian', 'rhine', 'levant', 'iraq', 'caucasus', 'mesopotamia', 'iraqi']), ('Tigris', ['indus', 'jordan', 'ara', 'swat', 'caspian', 'red', 'nile', 'acheron', 'yellow', 'syrian']), (',', ['the', ',', '.', 'of', '-', 'and', 'a', 'to', 'as', 'in'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 22/100 [02:13<14:08, 10.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Judgment', ['judgment', 'judgement', 'memorial', 'independence', 'fight', 'graduation', 'labor', 'revenge', 'thanksgiving', 'trial']), ('successfully', ['successfully', 'unsuccessfully', 'successful', 'effectively', 'victorious', 'unopposed', 'unsuccessful', 'independently', 'again', 'weakly']), ('Melina', ['victoria', 'melissa', 'paige', 'raven', 'stephanie', 'serena', 'tara', 'phoenix', 'naomi', 'maria'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 23/100 [02:29<16:09, 12.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', ['to', 'towards', 'including', 'through', 'into', ',', 'and', 'over', 'on', 'of']), ('partnerships', ['partnerships', 'partners', 'partnership', 'relationships', 'marriages', 'unions', 'couples', 'singles', 'alliances', 'weddings']), ('partners', ['.', 'the', ')', '-', \"'\", ',', 'of', 'a', ';', '##s']), ('benefits', ['benefits', 'benefit', 'privileges', 'welfare', 'advantages', 'services', 'protections', 'benefited', 'blessings', 'products']), (';', [';', ',', '.', ':', 'and', '-', 'but', '(', ')', '{']), ('ranging', ['ranging', 'range', 'varying', 'ranges', 'specialising', 'running', 'differing', 'ranged', 'spectrum', 'moving']), ('exemptions', ['exemption', 'breaks', 'benefits', 'advantages', 'credits', 'exempt', 'reliefs', 'relief', 'exceptions', 'immunity']), ('property', ['property', 'possession', 'ownership', 'estate', 'legal', 'residence', 'inheritance', 'properties', 'land', '##uity']), (',', ['to', 'towards', 'including', 'through', 'into', ',', 'and', 'over', 'on', 'of']), ('status', ['status', 'standing', 'position', 'rights', 'recognition', '##hood', 'rank', '##hip', 'condition', 'relations']), ('parenting', ['parenting', 'parental', 'family', 'living', 'preschool', 'housing', 'nesting', 'stepmother', 'paternal', 'custody']), ('responsibilities', ['.', 'responsibilities', ';', 'responsibility', 'duties', 'roles', 'powers', 'obligations', 'rights', 'burden'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 24/100 [02:29<11:17,  8.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bursa', ['istanbul', 'ankara', 'turkey', 'sarajevo', 'sofia', 'tirana', 'cyprus', 'it', 'baku', 'constantinople'])]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 26/100 [02:38<09:20,  7.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Manchester', ['the', ',', '.', 'of', 'a', 'as', 'and', 'to', 'in', '-']), ('customs', ['customs', 'commercial', 'border', 'trade', 'custom', 'trading', 'naval', 'free', 'maritime', 'police']), (',', [',', '.', ';', '-', 'and', 'just', ':', 'only', 'about', '(']), ('opening', ['opening', 'completion', 'establishment', 'construction', 'creation', 'opened', 'closure', 'inauguration', 'closing', 'introduction']), ('Manchester', ['the', ',', '.', 'of', 'a', 'as', 'and', 'to', 'in', '-']), ('Manchester', ['the', ',', '.', 'of', 'a', 'as', 'and', 'to', 'in', '-']), ('landlocked', ['port', 'coastal', 'trading', 'metropolitan', 'harbour', 'canal', 'border', 'separate', 'free', 'merchant'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 27/100 [02:43<08:17,  6.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hofstetten-Fl', ['fl', 'st', 'mont', 'la', '##fl', 'val', 'the', 'ben', '-', 'sur']), ('üh', ['##ach', '##ein', '##on', '##en', '##ott', '##am', '##ensburg', '##az', '##orin', '##as']), ('municipality', ['municipality', 'village', 'town', 'community', 'settlement', 'hamlet', 'quarter', 'city', 'township', 'municipalities']), ('district', ['district', 'arrondissement', 'districts', 'municipality', 'canton', 'region', 'county', 'parish', 'department', 'constituency']), ('Dorneck', ['stein', 'buren', 'baden', 'constance', 'wil', 'toss', '##ried', 'brig', 'zurich', 'land']), ('canton', ['canton', 'region', 'district', 'state', 'east', 'south', 'province', 'city', 'county', 'municipality']), ('Solothurn', ['zurich', 'bern', 'basel', 'baden', 'lausanne', 'canton', 'constance', 'buren', 'geneva', '##nger'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 28/100 [02:44<05:51,  4.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Rhineland-Palatinate', ['hesse', 'germany', 'rhineland', 'france', 'dusseldorf', 'bavaria', 'palatinate', 'trier', 'mainz', 'palatine'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 29/100 [02:49<05:47,  4.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Zeta', ['epsilon', 'zeta', 'alpha', 'beta', 'eighteen', 'mira', 'zero', 'seventeen', 'x', 'alfa']), ('late-developing', ['weak', 'developing', 'strong', 'weakening', 'severe', 'powerful', 'small', 'late', 'strengthening', 'large']), ('hurricane', ['hurricane', 'cyclone', 'typhoon', 'hurricanes', 'storm', 'depression', 'flooding', 'storms', 'tropical', 'tornado']), ('officially', ['officially', 'formally', 'already', 'actually', 'official', 'effectively', 'legally', 'explicitly', 'finally', 'unofficially']), (',', [',', ';', '.', '-', 'and', '...', ')', 'early', 'before', '('])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 30/100 [02:52<05:04,  4.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hellhound', ['hound', 'werewolf', 'wolf', 'devil', 'dog', 'demon', 'vampire', 'beast', 'dragon', 'phantom']), (',', ['folklore', 'mythology', 'legend', 'lore', 'legends', 'underworld', 'folk', 'mythical', 'mythological', 'occult']), ('mythology', ['mythology', 'myth', 'myths', 'legend', 'fantasy', 'mythological', 'history', 'legends', 'folklore', 'antiquity']), (',', ['folklore', 'mythology', 'legend', 'lore', 'legends', 'underworld', 'folk', 'mythical', 'mythological', 'occult']), ('folklore', ['folklore', 'folk', 'lore', 'literature', 'tradition', 'legend', 'legends', 'history', 'mythology', 'myth']), ('fiction', ['.', 'fiction', ';', 'fantasy', 'literature', 'story', 'novel', '...', '?', '!'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 31/100 [02:53<03:51,  3.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('breaking', ['breaking', 'break', 'broke', 'splitting', 'turning', 'broken', 'breaks', 'cutting', 'running', 'pulling']), ('Century', ['century', '-', 'millennium', 'centuries', 'street', '&', 'vantage', 'temple', 'and', 'alliance'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 32/100 [03:29<15:04, 13.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('-', ['-', '+', '%', 'm', 'km', 'kilometres', 'cm', '##°', 'times', 'metres']), (',', ['they', 'them', 'their', 'are', 'ice', ',', 'these', '##s', 'that', 'it']), ('resulting', ['resulting', 'resulted', 'result', 'results', 'culminating', 'bringing', 'resultant', 'participating', 'corresponding', 'ending']), ('icebergs', ['further', 'deeper', 'farther', 'higher', 'lower', 'deep', 'far', 'shallow', 'more', '##er']), ('calved', ['broken', 'cut', 'lifted', 'breaking', 'blown', 'knocked', 'torn', 'melted', 'broke', 'lifting']), ('passing', ['passing', 'passed', 'pass', 'traveling', 'falling', 'passes', 'moving', 'travelling', 'reaching', 'passage']), ('fjord', ['the', 'this', 'a', 'my', 'his', '-', 'that', 'its', 'your', 'our']), ('Icebergs', ['rocks', 'boulders', 'ice', 'glaciers', 'waves', 'stones', 'blocks', 'sediments', 'debris', 'ships']), ('breaking', ['breaking', 'forming', 'bursting', 'emerging', 'falling', 'separating', 'broken', 'issuing', 'cracking', 'striking']), ('fjord', ['the', 'this', 'a', 'my', 'his', '-', 'that', 'its', 'your', 'our']), ('shallower', ['shallow', 'deeper', 'deep', 'deepest', 'depth', 'sandy', 'superficial', 'lower', 'sheltered', 'moist']), ('areas', ['areas', 'parts', 'area', 'sections', 'regions', 'fields', 'zones', 'places', 'stretches', 'spaces']), (',', ['they', 'them', 'their', 'are', 'ice', ',', 'these', '##s', 'that', 'it']), (',', ['they', 'them', 'their', 'are', 'ice', ',', 'these', '##s', 'that', 'it']), ('icebergs', ['further', 'deeper', 'farther', 'higher', 'lower', 'deep', 'far', 'shallow', 'more', '##er']), ('fjord', ['the', 'this', 'a', 'my', 'his', '-', 'that', 'its', 'your', 'our'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 33/100 [03:30<10:30,  9.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('devotion', ['.', '!', '?', '|', '...', ';', '-', '॥', ',', \"'\"])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 34%|███▍      | 34/100 [03:30<07:30,  6.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('population', ['population', 'enrollment', 'estimate', 'census', 'populace', 'count', 'total', 'attendance', 'community', 'populations']), ('census', ['census', '.', ';', 'estimate', 'estimates', 'election', '?', '|', 'list', '!'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 35/100 [03:32<05:42,  5.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Founding', ['founding', 'former', 'current', 'founder', 'original', 'charter', 'defunct', 'foundation', 'past', 'full']), ('members', ['members', 'member', 'clubs', 'membership', 'players', 'champions', 'teams', 'presidents', 'sponsors', 'participants']), ('Premier', ['premier', 'football', 'super', 'champions', 'national', 'europa', 'amateur', 'southern', 'professional', 'reserve']), ('italics', ['bold', 'italics', '.', ';', ':', '|', '[UNK]', '?', 'key', 'brackets'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|███▌      | 36/100 [03:39<06:12,  5.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('areas', ['areas', 'area', 'regions', 'parts', 'portions', 'elements', 'lines', 'patches', 'places', 'spaces']), ('`', ['black', 'white', 'blackness', 'grey', 'dark', 'red', 'gray', 'blue', 'blackish', 'brown']), ('chisel', ['hammer', 'scissors', 'saw', 'knife', 'tool', 'laser', 'axe', 'pencil', 'blade', 'shear']), (',', [',', ';', '.', 'and', 'while', '-', ':', '...', 'but', 'only']), ('characters', ['characters', 'character', 'text', 'figures', 'lines', 'words', 'symbols', 'parts', 'elements', 'digits']), ('image', ['image', 'images', 'picture', 'imagery', 'artwork', 'pictures', 'scene', 'object', 'logo', 'imaging']), ('`', ['black', 'white', 'blackness', 'grey', 'dark', 'red', 'gray', 'blue', 'blackish', 'brown'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|███▋      | 37/100 [03:41<04:45,  4.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Owyhee', ['blaine', 'custer', 'bingham', 'idaho', 'fremont', 'cache', 'lewis', 'wheeler', 'franklin', 'boise']), (',', ['.', 'the', ')', ';', '-', ',', 'of', 'a', \"'\", 's']), (',', ['.', 'the', ')', ';', '-', ',', 'of', 'a', \"'\", 's'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 38/100 [03:43<03:58,  3.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('quartet', ['quartet', 'ensemble', 'group', 'trio', 'quintet', 'orchestra', 'band', 'duo', 'choir', 'team']), ('Musikverein', ['festival', 'biennale', 'philharmonic', 'conservatory', 'secession', 'opera', 'arena', 'academy', 'carnival', 'biennial']), ('Amsterdam', ['amsterdam', 'rotterdam', 'holland', 'paris', 'dutch', 'vienna', 'brussels', 'utrecht', 'london', 'frankfurt']), ('Concertgebouw', ['.', ';', 'festival', 'philharmonic', '!', '?', 'conservatory', 'concert', 'biennale', 'forum'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███▉      | 39/100 [03:49<04:32,  4.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('intense', ['intense', 'active', 'intensity', 'powerful', 'vigorous', 'intensified', 'intensive', 'severe', 'organized', 'aggressive']), ('hurricane', ['hurricane', 'cyclone', 'storm', 'tropical', 'mitch', 'hurricanes', 'typhoon', 'system', 'gale', 'depression']), ('cyclone', ['cyclone', 'storm', 'hurricane', 'depression', 'system', 'cyclones', 'typhoon', 'disturbance', 'rainfall', 'tornado']), ('hurricane', ['hurricane', 'cyclone', 'storm', 'tropical', 'mitch', 'hurricanes', 'typhoon', 'system', 'gale', 'depression']), ('hurricane', ['hurricane', 'cyclone', 'storm', 'tropical', 'mitch', 'hurricanes', 'typhoon', 'system', 'gale', 'depression']), ('hurricane', ['hurricane', 'cyclone', 'storm', 'tropical', 'mitch', 'hurricanes', 'typhoon', 'system', 'gale', 'depression'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 40/100 [03:59<06:17,  6.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Tracy', ['tracy', 'it', 'ike', 'columbia', 'flooding', 'katrina', 'earthquake', 'this', 'hurricane', 'andrew']), (',', ['including', 'destroyed', 'included', 'impacted', 'of', 'over', 'damaged', ',', 'on', 'about']), ('$', ['$', 'dollar', 'usd', 'dollars', 'money', '€', 'over', 'rm', 'revenue', 'fr']), ('destroyed', ['destroyed', 'ruined', 'demolished', 'damaged', 'destruction', 'wrecked', 'destroying', 'destroy', 'devastated', 'ruin']), ('percent', [',', 'the', '.', 'of', 'and', 'to', 'as', '-', 'a', 'in']), ('Darwin', [\"'\", '`', 'washington', 'florida', 'california', 'area', 'atlanta', 'city', 'state', 'district']), ('buildings', ['buildings', 'structures', 'building', 'houses', 'properties', 'facilities', 'property', 'blocks', 'businesses', 'housing']), (',', ['including', 'destroyed', 'included', 'impacted', 'of', 'over', 'damaged', ',', 'on', 'about']), ('including', ['including', 'included', 'destroyed', 'destroying', 'and', 'damaged', 'ruined', 'involving', 'includes', 'or']), ('percent', [',', 'the', '.', 'of', 'and', 'to', 'as', '-', 'a', 'in']), ('houses', ['houses', '.', ';', 'buildings', 'homes', 'schools', 'dwellings', 'streets', '?', 'blocks'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|████      | 41/100 [04:00<04:33,  4.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('multiple', ['multiple', 'twin', 'train', 'single', 'triple', 'locomotive', 'quad', 'series', 'multi', 'dual'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 42/100 [04:01<03:16,  3.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Marco', ['gloria', 'brenda', 'frances', 'debbie', 'rita', 'marco', 'jeanne', 'maria', 'danny', 'jackie'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 43/100 [04:09<04:44,  4.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sergio', ['sergio', 'diego', 'jorge', 'marco', 'fernando', 'cesar', 'marcos', 'garcia', 'rodrigo', 'benito']), ('Rodríguez', ['rodriguez', 'garcia', 'guerrero', 'munoz', 'sanchez', 'martinez', 'gonzalez', 'ramirez', 'lopez', 'delgado']), ('García', ['garcia', 'rodriguez', 'fernandez', 'martinez', 'hernandez', 'lopez', 'gomez', 'sanchez', 'diaz', 'guerrero']), (',', [',', 'the', 'a', 'as', '.', 'of', '-', 'in', 'an', 'and']), ('Rodri', ['sergio', 'marco', 'jorge', 'cesar', 'diego', 'toni', 'mario', 'rudy', 'nico', 'leo']), (',', [',', 'the', 'a', 'as', '.', 'of', '-', 'in', 'an', 'and']), ('footballer', ['footballer', 'football', 'player', 'defender', 'cyclist', 'footballers', 'professional', 'midfielder', 'actor', 'forward']), ('currently', ['currently', 'current', ',', 'presently', 'previously', 'now', 'recently', 'formerly', 'primarily', 'who']), ('playing', ['playing', 'working', 'plays', 'appearing', 'competing', 'featuring', 'played', 'practicing', 'play', 'writing']), ('Hércules', ['hercules', 'cordoba', 'granada', 'cadiz', 'malaga', 'valencia', 'ares', 'fatima', 'salamanca', 'pena']), (',', [',', 'the', 'a', 'as', '.', 'of', '-', 'in', 'an', 'and']), ('mainly', ['mainly', 'primarily', 'usually', 'mostly', 'principally', 'predominantly', 'generally', 'also', 'commonly', 'often']), ('defender', ['.', 'defender', ';', 'midfielder', 'striker', 'player', 'forward', 'attacker', 'defensive', '!'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 44/100 [04:29<08:39,  9.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('highly', ['highly', 'heavily', 'extremely', 'very', 'strongly', 'mildly', 'deeply', 'greatly', 'moderately', 'fully']), ('Volkswagen', ['volkswagen', 'porsche', 'fiat', 'audi', 'ford', 'bmw', 'chevrolet', 'volvo', 'beetle', 'diesel']), ('engines', ['hybrids', 'hybrid', 'ev', 'series', 'gen', 'cars', 'car', 'vehicles', 'van', 'suv']), ('hybrids', ['hybrids', 'cars', 'vehicles', 'hybrid', 'conversions', 'models', 'variants', '##vs', '##bians', 'twins']), ('Pinto', ['pinto', 'mustang', 'v8', 'continental', 'fiesta', 'automobile', '##uto', 'chrome', '##sun', '##eto']), (',', ['or', 'and', '/', ',', '-', 'of', 'with', 'to', 'on', 'nor']), ('Chevrolet', ['chevrolet', 'chevy', 'pontiac', 'holden', 'gm', 'buick', 'cadillac', 'volkswagen', 'corvette', 'ford']), ('Corvair', ['corvette', 'engine', 'pinto', 'vega', 'v8', 'diesel', 'seville', 'cobalt', 'chevrolet', 'santana']), (',', ['or', 'and', '/', ',', '-', 'of', 'with', 'to', 'on', 'nor']), (',', ['or', 'and', '/', ',', '-', 'of', 'with', 'to', 'on', 'nor']), (',', ['or', 'and', '/', ',', '-', 'of', 'with', 'to', 'on', 'nor']), ('Subaru', ['volkswagen', 'mitsubishi', 'toyota', 'bmw', 'audi', 'volvo', 'suzuki', 'nissan', 'fiat', 'mazda']), ('-', ['.', 'the', ')', '-', \"'\", ',', ';', 'of', 'a', '##s']), ('eight-cylinder', ['eight', 'six', 'four', 'five', '8', 'seven', 'sixteen', 'twelve', 'nine', '6']), ('engines', ['hybrids', 'hybrid', 'ev', 'series', 'gen', 'cars', 'car', 'vehicles', 'van', 'suv'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 45/100 [04:30<06:25,  7.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', [',', 'john', '.', 'arthur', ':', 'william', 'edward', 'jean', ';', 'robert']), ('Steinbeck', ['he', 'she', 'hemingway', 'joyce', 'poe', 'dickens', 'it', 'melville', 'eliot', 'twain']), ('Nobel', ['pulitzer', 'nobel', 'academy', 'orange', 'israel', 'national', 'rome', 'jerusalem', 'international', 'caine']), ('Literature', ['literature', 'fiction', 'poetry', '.', 'nonfiction', 'writing', 'journalism', 'biography', 'art', 'philosophy'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|████▌     | 46/100 [04:34<05:21,  5.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Weighing', ['weighing', 'weighed', 'weigh', 'weighs', 'weight', 'weighted', 'weights', 'carrying', 'measuring', 'at']), (',', ['he', 'all', 'a', 'al', 'i', 'baseball', 'the', 'or', 'era', 'game']), ('standing', ['standing', 'sitting', 'stands', 'measuring', 'stood', 'stand', 'being', '##standing', 'kneeling', 'appearing']), (',', ['he', 'all', 'a', 'al', 'i', 'baseball', 'the', 'or', 'era', 'game']), ('shortest', ['shortest', 'smallest', 'tallest', 'heaviest', 'youngest', 'oldest', 'longest', 'largest', 'lowest', 'fastest'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|████▋     | 47/100 [04:35<03:54,  4.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Veterans', ['veterans', 'veteran', 'military', 'defense', 'homeland', 'state', 'civil', 'naval', 'foreign', 'army']), ('Affairs', ['.', ';', '?', '!', '...', '|', ',', ':', 'and', '।'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 48/100 [04:38<03:35,  4.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', ['but', 'though', 'although', 'however', 'while', 'and', 'as', 'yet', 'when', 'except']), ('Amritsar', ['lahore', 'peshawar', 'islamabad', 'karachi', 'punjab', 'jammu', 'delhi', 'hyderabad', 'ahmedabad', 'punjabi']), (',', ['but', 'though', 'although', 'however', 'while', 'and', 'as', 'yet', 'when', 'except']), ('violence', ['violence', 'fighting', 'clashes', 'gunfire', 'hostilities', 'violent', 'conflict', 'riots', 'incidents', 'combat']), ('Punjab', ['punjab', '.', ';', 'city', 'province', 'state', '|', 'country', 'district', '?'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|████▉     | 49/100 [04:40<02:52,  3.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('especially', ['especially', 'more', 'extremely', 'particularly', 'most', 'less', 'also', 'very', 'not', 'highly']), ('islands', ['islands', 'island', 'isles', 'reefs', 'beaches', 'shores', 'coasts', 'islanders', 'archipelago', 'continents']), ('isolation', ['isolation', '.', 'location', 'proximity', 'isolated', 'isolate', 'distance', 'distribution', 'locality', 'separation'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 50/100 [04:46<03:29,  4.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Kilner', ['co', 'company', 'sons', 'brothers', 'son', 'brother', 'manufacturers', 'manufacturing', 'firm', 'patent']), ('Kilner', ['co', 'company', 'sons', 'brothers', 'son', 'brother', 'manufacturers', 'manufacturing', 'firm', 'patent']), ('associates', ['associates', 'partners', 'associate', 'brothers', 'colleagues', 'partner', 'assistants', 'brother', 'others', 'friends']), ('later', ['later', 'subsequently', 'also', 'eventually', 'then', 'afterwards', 'first', 'originally', 'previously', 'soon']), ('Kilner', ['co', 'company', 'sons', 'brothers', 'son', 'brother', 'manufacturers', 'manufacturing', 'firm', 'patent']), ('&', ['&', 'and', '+', 'et', ',', 'or', '-', '/', '.', \"'\"])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████     | 51/100 [05:00<05:46,  7.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('satellites', ['satellites', 'moons', 'planets', 'satellite', 'rings', 'components', 'objects', 'comets', 'bodies', 'moon']), ('Uranus', ['saturn', 'jupiter', 'neptune', 'mercury', 'mars', 'venus', 'earth', 'pluto', 'europa', 'sirius']), ('Herschel', ['franklin', 'pickering', 'palmer', 'lowell', 'greenwich', 'gould', 'barnard', 'moon', 'lawrence', 'adams']), (',', [',', 'the', '.', 'of', 'and', 'a', 'as', 'that', 'in', 'to']), ('request', ['request', 'suggestion', 'invitation', 'requested', 'recommendation', 'desire', 'visit', 'wish', 'query', 'requesting']), ('Lassell', ['pickering', 'brewster', 'warner', 'thomson', 'dick', 'armstrong', 'brown', 'gilbert', 'franklin', 'marsden']), (',', [',', 'the', '.', 'of', 'and', 'a', 'as', 'that', 'in', 'to']), (',', [',', 'the', '.', 'of', 'and', 'a', 'as', 'that', 'in', 'to']), ('Umbriel', ['ariel', 'phoebe', 'europa', 'merlin', 'io', 'venus', 'vega', 'mercury', 'minerva', 'sirius']), (',', [',', 'the', '.', 'of', 'and', 'a', 'as', 'that', 'in', 'to'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 52/100 [05:01<04:13,  5.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Eastoe', ['henry', 'william', 'george', 'edward', 'charles', 'john', 'james', 'francis', 'thomas', 'richard']), ('Abbott', ['abbott', 'abbot', 'abbey', 'newman', 'stevens', 'foster', ',', 'marshall', 'lamb', 'mason']), ('poet', ['.', 'poet', 'politician', 'writer', 'composer', 'author', 'clergyman', 'sculptor', 'painter', 'musician'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|█████▎    | 53/100 [05:02<03:13,  4.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pansori', ['pan', '[UNK]', 'san', 'mani', 'para', 'so', 'banda', 'sri', 'maya', 'bali']), (',', [',', '##a', '##s', '##i', '##na', '-', '##e', '##o', '##n', '.']), ('sori', ['is', 'pan', 'it', '-', 'music', 'form', 'dish', 'fish', 'food', 'tuning'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|█████▍    | 54/100 [05:04<02:33,  3.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', [',', 'the', '.', 'and', '-', ':', ';', 'a', '&', ')']), ('Bloodhound', ['blood', 'the', 'death', 'wolf', 'vampire', 'hell', 'vicious', 'motorcycle', 'chain', 'monster']), ('albums', ['.', ';', '!', 'albums', 'records', 'singles', '?', 'songs', 'album', '|'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 55/100 [05:09<02:57,  3.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', [',', '.', ';', ':', '-', '...', 'and', 'if', 'when', 'also']), ('orientation', ['orientation', 'relationship', 'interest', 'partner', 'preference', 'attraction', 'attitude', 'expression', 'component', 'identity']), ('commonly', ['commonly', 'widely', 'frequently', 'recently', 'often', 'rarely', 'typically', 'generally', 'usually', 'previously']), ('incidence', ['incidence', 'prevalence', 'occurrence', 'annual', 'overall', 'average', 'prevalent', 'percentage', 'case', 'instance']), ('asexuality', ['homosexuality', 'abortion', 'hiv', 'divorce', 'transgender', 'fertility', 'sexuality', 'bisexual', 'depression', 'rape']), ('%', ['%', ';', '.', '|', '?', '!', '।', 'percent', '+', 'percentage'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 56/100 [05:11<02:25,  3.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', [',', '.', ':', ';', '-', 'and', '...', ')', 'where', 'when']), ('pillows', ['pillows', 'blankets', 'beds', 'furniture', 'clothing', 'cushions', 'covers', 'curtains', 'sheets', 'walls']), ('nightmares', ['.', ';', '!', '?', '...', ',', ':', '|', '।', ')'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████▋    | 57/100 [05:40<07:52, 10.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Demand', ['demand', 'need', 'charge', 'command', '##box', 'press', 'call', 'order', 'depth', 'response']), (',', ['with', ',', 'and', 'at', '.', '(', 'which', 'where', '\"', 'featuring']), ('concerts', ['concerts', 'concert', 'music', 'performances', 'tournaments', 'shows', 'festivals', 'television', 'sports', 'musicals']), (',', ['with', ',', 'and', 'at', '.', '(', 'which', 'where', '\"', 'featuring']), (',', ['with', ',', 'and', 'at', '.', '(', 'which', 'where', '\"', 'featuring']), ('ranging', ['from', 'between', 'up', 'to', 'at', '$', 'for', 'through', 'on', 'around']), ('$', ['##9', '##8', '##7', '##4', '.', '##1', '##°', '##6', 'daphne', '##3']), ('$', ['##9', '##8', '##7', '##4', '.', '##1', '##°', '##6', 'daphne', '##3']), (',', ['with', ',', 'and', 'at', '.', '(', 'which', 'where', '\"', 'featuring']), ('Showtime', ['showtime', 'wwe', 'fox', 'espn', 'fx', 'hbo', 'lifetime', 'ufc', 'nfl', 'cbs']), (',', ['with', ',', 'and', 'at', '.', '(', 'which', 'where', '\"', 'featuring']), ('TVKO', ['tv', '##tv', 'television', ',', 'hd', 'sports', 'cable', 'live', 'premium', 'espn']), (',', ['with', ',', 'and', 'at', '.', '(', 'which', 'where', '\"', 'featuring']), ('championship', ['championship', 'professional', 'title', 'pro', 'tournament', 'champion', 'exhibition', 'amateur', 'knockout', 'regulation']), ('boxing', ['boxing', 'fighting', 'wrestling', 'fights', 'bouts', '##fighting', 'boxers', 'mma', 'matches', 'boxer']), ('ranging', ['from', 'between', 'up', 'to', 'at', '$', 'for', 'through', 'on', 'around']), ('$', ['##9', '##8', '##7', '##4', '.', '##1', '##°', '##6', 'daphne', '##3']), ('$', ['##9', '##8', '##7', '##4', '.', '##1', '##°', '##6', 'daphne', '##3'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|█████▊    | 58/100 [05:45<06:30,  9.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Southampton', ['london', 'portsmouth', 'bournemouth', 'bristol', 'brighton', 'southampton', 'sheffield', 'reading', 'birmingham', 'nottingham']), ('Tramways', ['trams', 'railways', 'tramway', 'services', 'buses', 'docks', 'works', 'corporation', 'stations', 'tram']), ('mainly', ['mainly', 'partly', 'primarily', 'mostly', 'largely', 'principally', 'also', 'predominantly', 'chiefly', 'heavily']), ('issues', ['issues', 'problems', 'concerns', 'conflicts', 'changes', 'issue', 'incidents', 'conditions', 'difficulties', 'requirements']), ('introduction', ['introduction', 'introduced', 'advent', 'introducing', 'introduce', 'application', 'arrival', 'addition', 'innovation', 'adoption']), ('female', ['male', 'female', 'women', 'woman', 'males', 'girl', 'females', 'men', 'girls', 'man']), ('``', ['`', \"'\", '′', '-', '\"', 'army', 'brigade', 'officers', 'superintendent', 'service']), ('conductorettes', ['.', 'conductors', 'conductor', ';', 'operators', 'drivers', 'operator', '|', 'staff', 'commissioners'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|█████▉    | 59/100 [05:53<06:00,  8.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Albacete', [',', 'the', '.', 'a', 'of', '-', 'in', 'as', 'and', 'to']), ('Balompié', ['cf', 'deportivo', 'atletico', 'b', 'fc', 'cd', 'ud', 'ac', 'handball', 'cb']), (',', [',', 'the', '.', 'a', '-', 'of', 'and', 'in', 'as', ')']), ('Albacete', [',', 'the', '.', 'a', 'of', '-', 'in', 'as', 'and', 'to']), (',', [',', 'the', '.', 'a', '-', 'of', 'and', 'in', 'as', ')']), ('community', ['community', 'communities', 'region', 'area', 'system', 'government', 'state', 'association', 'body', 'university']), ('Castile-La', ['la', 'alta', 'primera', 'segunda', 'northern', 'the', 'a', 'santa', 'greater', 'el']), ('Mancha', ['.', ';', '!', '|', '।', '?', 'union', 'sierra', '...', 'real'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 60/100 [05:56<04:47,  7.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Momentum', ['momentum', 'energy', 'velocity', 'position', 'time', 'mass', 'motion', 'space', 'charge', 'frequency']), ('quantity', ['quantity', 'measure', 'property', 'quantities', 'variable', 'relation', 'constant', 'substance', 'term', 'concept']), (',', [',', ';', '.', '-', ':', 'and', '...', '(', ')', 'of']), ('meaning', ['meaning', 'means', 'saying', 'mean', 'so', 'meant', 'implying', 'stating', 'such', 'indicating']), ('momentum', ['momentum', 'velocity', 'energy', 'motion', 'mass', 'position', 'weight', 'entropy', 'spin', 'speed']), ('system', ['system', 'systems', 'body', 'state', 'structure', 'process', 'set', 'form', 'subject', 'matter'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|██████    | 61/100 [06:01<04:16,  6.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Saint-Jean-de-Monts', ['mont', 'bois', 'croix', 'mons', 'champs', 'pont', 'bellevue', 'fontaine', 'camps', 'nes']), ('commune', ['commune', 'village', 'communes', 'department', 'town', 'municipality', 'canton', 'parish', 'valley', 'chateau']), ('Vendée', ['cher', 'loire', 'lot', 'ain', 'somme', 'centre', 'maine', 'var', 'blanc', 'same']), ('department', ['department', 'departments', 'dept', ',', 'and', 'est', 'district', 'valley', 'arrondissement', 'et']), ('Loire', ['loire', 'cher', 'cote', 'somme', 'nouvelle', 'basque', 'bray', 'lot', 'main', 'haute']), ('region', ['region', 'area', 'regional', 'regions', 'district', 'department', 'province', 'zone', ',', 'and'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████▏   | 62/100 [06:11<04:49,  7.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('carnivorous', ['marine', 'predatory', 'terrestrial', 'freshwater', '##nivorous', 'aquatic', 'edible', 'parasitic', 'living', 'giant']), ('sponges', ['sponge', 'organisms', 'plants', 'algae', 'bacteria', 'species', 'invertebrates', 'squid', 'snails', 'ferns']), ('waters', ['waters', 'water', 'seas', '##water', 'oceans', 'depths', 'ocean', 'sea', 'reefs', 'areas']), (',', ['the', ',', '.', 'of', 'a', 'to', 'that', 'and', 'as', 'in']), (',', ['the', ',', '.', 'of', 'a', 'to', 'that', 'and', 'as', 'in']), ('development', ['development', 'use', 'developing', 'evolution', 'advancement', 'develop', 'advance', 'developed', 'introduction', 'study']), ('exploration', ['exploration', 'drilling', 'research', 'search', 'exploring', 'explorer', 'discovery', 'sampling', 'searching', 'investigation']), ('techniques', ['techniques', 'methods', 'technique', 'strategies', 'technologies', 'tools', 'processes', 'technology', 'mechanisms', 'materials']), ('discovery', ['discovery', 'discoveries', 'discovered', 'finding', 'discovering', 'discover', 'presence', 'detection', 'creation', 'revelation'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|██████▎   | 63/100 [06:30<06:48, 11.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ghulam', ['muhammad', 'imam', 'abdullah', 'ali', 'mirza', 'ahmad', 'akbar', 'hasan', 'syed', 'shah']), ('Ahmad', ['ahmad', 'muhammad', 'mohammed', 'ali', 'hussain', 'mohammad', 'ahmed', 'mustafa', 'abdullah', 'hussein']), ('prophecies', ['prophecy', 'predictions', 'dreams', 'promises', 'visions', 'prediction', 'claims', 'expectations', 'messages', 'announcements']), ('reformer', ['reformer', 'reform', 'reformation', 'conqueror', 'leader', 'revolutionary', '##izer', 'progressive', 'prophet', '##iser']), (',', [',', 'and', ';', '.', '-', ':', '/', '...', 'or', 'who']), ('herald', ['herald', 'announce', 'witness', 'deliver', 'hail', 'manifest', 'inspire', 'bring', 'initiate', 'hallmark']), ('Eschaton', ['apocalypse', 'messiah', 'jihad', 'revelation', 'dawn', 'resurrection', 'caliphate', 'revolution', 'light', 'victory']), ('traditions', ['traditions', 'tradition', 'teachings', 'practices', 'classics', 'histories', 'religions', 'beliefs', 'records', 'heritage']), ('religions', ['religions', 'religion', 'traditions', 'civilizations', 'cultures', 'countries', 'peoples', 'religious', 'societies', 'beliefs']), ('triumph', ['triumph', 'victory', 'defeat', 'victories', 'supremacy', 'glory', 'conquest', 'success', 'victorious', 'triumphant']), ('Islam', ['ic', 'international', 'asian', 'icc', 'm', 'african', 'islamic', '##c', 'in', 'world']), ('prophecy', ['prophecy', 'tradition', 'revelation', 'prediction', 'vision', 'messenger', 'doctrine', 'message', 'prophet', '.'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 64%|██████▍   | 64/100 [06:33<05:06,  8.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ratso', ['adamant', 'strong', 'strict', 'firm', 'stubborn', 'strongly', 'vocal', 'insists', 'the', 'insist']), (',', [',', '.', ';', '-', '...', ':', '!', 'again', '?', 'himself']), ('Ratso', ['adamant', 'strong', 'strict', 'firm', 'stubborn', 'strongly', 'vocal', 'insists', 'the', 'insist']), ('adamantly', ['still', 'again', 'flatly', 'politely', 'angrily', 'also', 'initially', 'repeatedly', 'strongly', 'immediately']), ('refuses', ['.', ';', '!', '?', '...', ':', '|', ',', '-', ')'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 65/100 [06:34<03:39,  6.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Reasoning', ['reasoning', 'ability', 'decision', 'comprehension', 'knowledge', 'mathematics', 'verbal', 'math', 'concept', 'composition']), ('admissions', ['admissions', 'admission', 'entrance', 'applications', 'entry', 'applicants', 'application', 'enrollment', 'acceptance', 'students'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 66%|██████▌   | 66/100 [06:35<02:36,  4.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('alphabet', ['alphabet', 'language', 'script', 'flag', 'name', 'bible', 'spelling', 'version', 'text', 'code']), ('letters', [';', '.', '!', '?', 'letters', 'consonants', 'characters', 'symbols', '|', 'vowels'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 67/100 [06:58<05:39, 10.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('``', ['.', 'the', ')', \"'\", ',', '-', ';', 'of', 'a', '##s']), ('Novels', ['novels', 'works', 'novel', 'writings', 'books', 'letters', 'essays', 'fiction', 'stories', 'prose']), (',', ['no', 'without', 'not', 'non', 'with', 'a', 'an', 'and', 'by', 'least']), ('anonymously', ['anonymous', 'posthumously', 'privately', 'separately', 'jointly', 'independently', 'alone', 'posthumous', 'publicly', 'online']), ('Blackwood', [\"'\", 'the', 'magazine', 'thomas', 'a', 'james', 'nature', 'literary', 'collier', 'brown']), (',', ['no', 'without', 'not', 'non', 'with', 'a', 'an', 'and', 'by', 'least']), ('Lewes', ['he', 'she', 'shelley', 'dickens', 'austen', 'wells', 'wilde', 'lewis', 'holmes', 'james']), ('novels', ['novels', 'novel', 'books', 'works', 'writings', 'novelist', 'prose', 'fiction', 'stories', 'trilogy']), ('``', ['.', 'the', ')', \"'\", ',', '-', ';', 'of', 'a', '##s']), ('economy', ['economy', 'efficiency', 'economics', 'equilibrium', 'energy', 'enterprise', 'industry', 'economies', 'economical', 'economic']), ('adaptation', ['adaptation', 'application', 'adapting', 'conversion', 'adaptations', 'adapt', 'extension', 'introduction', 'adjustment', 'development']), (',', ['no', 'without', 'not', 'non', 'with', 'a', 'an', 'and', 'by', 'least']), ('superfluous', ['unnecessary', '##ury', 'necessary', 'unpleasant', '##uous', '##ious', 'useless', 'other', 'excessive', 'trivial']), ('elements', ['elements', 'element', 'components', 'parts', 'ingredients', 'details', 'factors', 'characters', 'materials', 'features']), ('Shakespeare', ['.', ';', '?', '|', '!', '...', \"'\", '\"', '।', '-'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|██████▊   | 68/100 [06:59<03:59,  7.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Veterans', ['veterans', 'veteran', 'military', 'naval', 'defense', 'state', 'indian', 'public', 'consumer', 'internal']), ('Affairs', ['.', ';', '!', '?', '|', ',', '...', 'and', \"'\", ':'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|██████▉   | 69/100 [07:00<02:49,  5.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Wolfgang', ['wolfgang', 'jurgen', 'klaus', 'karl', 'peter', 'heinz', 'gunther', 'wolf', 'ludwig', 'michael']), ('Fahrian', ['schmidt', 'muller', 'wolf', 'walter', 'weber', 'fischer', 'schwarz', 'becker', 'koch', 'berger'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 70/100 [07:05<02:39,  5.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('digital', ['digital', 'physical', 'cd', 'music', 'download', 'visual', 'promotional', 'vocal', 'vinyl', 'remix']), ('featuring', ['featuring', 'starring', 'with', 'by', 'featured', 'including', 'features', 'containing', 'involving', 'using']), ('Jessica', ['jessica', 'jess', 'chloe', 'dinah', 'jessie', 'luke', 'eli', 'kylie', 'tiffany', 'jackson']), (',', ['roommate', 'bachelor', 'girlfriend', 'house', 'boyfriend', 'dorm', 'apartment', 'bedroom', 'student', 'home']), (',', ['roommate', 'bachelor', 'girlfriend', 'house', 'boyfriend', 'dorm', 'apartment', 'bedroom', 'student', 'home']), ('Seohyun', ['tiffany', 'kim', 'jessica', 'jade', 'michelle', 'amber', 'grace', 'lee', 'sunny', 'ryan']), (',', ['roommate', 'bachelor', 'girlfriend', 'house', 'boyfriend', 'dorm', 'apartment', 'bedroom', 'student', 'home']), ('Roommate', ['.', '?', ';', '!', '|', '...', '।', '[UNK]', \"'\", ','])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████   | 71/100 [07:08<02:17,  4.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tortoise', ['fish', 'bird', 'snake', 'turtle', 'rabbit', 'dove', 'deer', 'serpent', 'bee', 'rock']), (',', [',', '.', ';', '-', '...', ':', 'and', '?', ')', 'also']), ('apocryphal', ['.', ';', '!', '?', ',', '...', ':', 'and', ')', '-'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 72%|███████▏  | 72/100 [07:19<03:00,  6.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('conventionally', ['traditionally', 'formally', 'historically', 'generally', 'officially', 'popularly', 'commonly', 'universally', 'previously', 'widely']), ('emperors', ['emperors', 'kings', 'monarchs', 'rulers', 'emperor', 'presidents', 'dukes', 'gods', 'empress', 'dynasties']), ('``', ['`', \"'\", 'being', '′', '~', '*', ':', '·', '[UNK]', 'the']), ('Emperor', ['emperor', 'king', 'emperors', 'prince', 'empress', 'empire', 'imperial', 'tsar', 'lord', 'kaiser']), ('Kammu', ['ai', 'meiji', 'go', 'saga', 'yang', 'kan', 'kai', 'wen', 'sho', 'tai']), (',', [',', '-', 'and', '.', ';', 'as', ':', 'or', '...', 'of']), ('sovereign', ['sovereign', 'ruler', 'monarch', 'emperor', 'king', 'monarchs', 'rulers', 'president', 'ruling', 'emperors']), ('Yamato', ['jin', 'japanese', 'han', 'tang', 'sui', 'zhou', 'nara', 'song', 'imperial', 'shang']), ('dynasty', ['.', 'dynasty', ';', '|', 'court', '!', 'period', '?', 'succession', '[UNK]'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|███████▎  | 73/100 [07:23<02:32,  5.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('commonly', ['commonly', 'widely', 'frequently', 'often', 'typically', 'generally', 'popularly', 'usually', 'also', 'currently']), ('``', ['`', \"'\", 'the', 'le', 'outside', 'la', 'monaco', 'el', 'a', 'little']), ('Carlo', ['neighborhood', 'district', 'suburb', 'quarter', 'area', 'community', 'ward', 'section', 'sector', 'neighbourhood']), ('largely', ['largely', 'located', 'mostly', 'somewhat', 'partially', 'partly', 'entirely', 'completely', 'primarily', 'situated']), ('Carlo', ['neighborhood', 'district', 'suburb', 'quarter', 'area', 'community', 'ward', 'section', 'sector', 'neighbourhood']), ('Monaco', ['monaco', '.', ';', '?', '|', '...', 'florida', '[UNK]', 'london', 'france'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 74%|███████▍  | 74/100 [07:25<01:57,  4.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', [',', '.', ';', 'and', '-', 'in', 'to', 'from', 'of', ')']), ('attended', ['attended', 'entered', 'attend', 'studied', 'attending', 'joined', 'attends', 'completed', 'graduated', 'visited']), ('Lauderdale', ['lauderdale', '.', 'myers', ';', 'worth', 'hare', '!', 'miami', 'erie', 'wayne'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 75/100 [07:28<01:48,  4.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Guitar', ['hero', 'heroes', 'mario', 'pro', 'player', 'superstar', 'factor', 'party', 'guitar', 'master']), ('Encore', ['encore', 'live', 'iii', 'iv', 'ii', '3', '3d', '2', '4', '5']), (':', [':', '-', '...', ',', '/', '2', '!', 'ii', '.', '3']), ('installment', ['installment', 'entry', 'game', 'title', 'release', 'chapter', 'volume', 'expansion', 'compilation', 'album']), ('Guitar', ['hero', 'heroes', 'mario', 'pro', 'player', 'superstar', 'factor', 'party', 'guitar', 'master']), ('series', ['.', ';', '!', '?', '...', '|', 'series', ':', ',', '．'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|███████▌  | 76/100 [07:32<01:39,  4.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('propositions', ['proposals', 'discussions', 'talks', 'suggestions', 'ideas', 'questions', 'concerns', 'negotiations', 'rumours', 'attempts']), ('including', ['including', 'having', 'adding', 'excluding', 'inclusion', 'include', 'included', 'incorporating', 'allowing', 'involving']), ('members', ['members', '##s', 'representatives', 'people', 'member', 'citizens', 'membership', 'candidates', 'mps', 'persons']), ('committee', ['committee', 'committees', 'assembly', 'group', 'council', 'commission', 'board', 'delegation', 'party', 'cabinet']), (',', [',', '.', ';', '-', '...', ':', 'and', '(', '?', ')']), ('happened', ['happened', 'happen', 'occurred', '.', 'happens', 'happening', 'done', 'materialized', 'existed', 'been'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 77%|███████▋  | 77/100 [07:34<01:18,  3.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('engines', ['engines', 'generators', 'pumps', 'turbines', 'sensors', 'collectors', '##ers', 'motors', 'drivers', 'vehicles']), ('cycles', ['cycles', 'processes', 'cycle', 'systems', 'engines', 'fuels', 'machines', 'technologies', 'vehicles', 'conditions']), ('attempt', ['attempt', 'try', 'seek', 'aim', 'propose', 'intend', 'attempted', 'attempts', 'attempting', 'endeavour']), ('mimic', ['.', ';', 'produce', 'simulate', 'reproduce', 'generate', 'make', 'perform', 'create', 'model'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 78/100 [07:34<00:55,  2.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Menestheus', [\"'\", 'the', 'alexander', 'hercules', 'zeus', 'constantine', 'john', 'achilles', 'thomas', 'ptolemy'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 79%|███████▉  | 79/100 [07:36<00:50,  2.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', ['although', 'though', 'however', 'despite', 'whilst', 'chapman', 'albeit', 'barnsley', '##sel', '##llus']), (',', ['although', 'though', 'however', 'despite', 'whilst', 'chapman', 'albeit', 'barnsley', '##sel', '##llus'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 80/100 [07:47<01:38,  4.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Forecasters', ['officials', 'they', 'observers', 'scientists', 'ships', 'experts', 'residents', 'forecast', 'leaders', 'pilots']), ('initially', ['initially', 'originally', 'first', 'earlier', 'initial', 'later', 'also', 'subsequently', 'early', 'previously']), ('Beryl', ['it', '##ryl', 'her', 'cindy', 'ida', 'gloria', 'felix', 'jim', 'pauline', 'connie']), ('Carolinas', ['bahamas', 'atlantic', 'coast', 'states', 'coastline', 'caribbean', 'keys', 'state', 'islands', 'region']), (';', [';', '.', 'and', ':', ',', '-', 'but', '(', 'as', 'or']), (',', [',', ';', ':', '.', '...', '-', 'and', 'only', 'however', 'the']), ('northward', ['northward', 'southward', 'westward', 'eastward', 'northwards', 'north', 'northwest', 'northeast', 'inland', 'northbound']), ('Currituck', ['virginia', 'myrtle', 'jacksonville', 'daytona', 'palm', 'carolina', 'navy', 'colonial', 'seal', 'atlantic']), ('Lighthouse', ['.', ';', '!', '?', '|', ',', ':', '...', '-', 'and'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|████████  | 81/100 [07:51<01:26,  4.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Assyrian', ['/', 'or', 'and', '-', 'cum', ',', 'of', 'x', '(', 'the']), ('Genocide', ['genocide', 'massacre', 'holocaust', 'atrocities', 'tragedy', 'war', 'question', 'revolt', 'famine', 'persecution']), ('Assyrian/Syriac', ['assyrian', 'christian', 'armenian', 'syriac', 'kurdish', 'greek', 'jewish', 'syrian', 'iraqi', 'arab']), ('population', ['population', 'people', 'community', 'populations', 'inhabitants', 'populace', 'minority', 'majority', '##s', 'residents']), ('Ottoman', ['ottoman', 'british', 'russian', 'turkish', 'byzantine', 'austrian', 'german', 'italian', 'assyrian', 'ethiopian']), ('Empire', ['empire', 'army', 'union', 'caliphate', 'era', 'empires', 'state', 'world', 'republic', 'realm'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|████████▏ | 82/100 [08:05<02:14,  7.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Corporation', ['corporation', 'inc', 'corp', 'networks', 'incorporated', 'studios', 'llc', 'software', 'technologies', 'company']), ('development', ['development', 'developer', 'production', 'developers', 'developed', 'creation', 'developing', 'software', 'design', 'company']), ('digital', ['digital', 'digitally', 'data', 'electronic', 'software', 'online', 'music', 'media', 'commercial', 'information']), ('distribution', ['distribution', 'distributor', 'distributing', 'distributed', 'download', 'licensing', 'distribute', 'entertainment', 'distributions', 'media']), ('Bellevue', ['bellevue', 'seattle', 'spokane', 'tacoma', 'washington', 'vancouver', 'olympia', 'northwest', 'everett', 'moines']), (',', ['in', 'on', 'the', 'at', '-', 'during', 'under', 'by', 'around', 'there']), (',', ['in', 'on', 'the', 'at', '-', 'during', 'under', 'by', 'around', 'there']), (',', ['in', 'on', 'the', 'at', '-', 'during', 'under', 'by', 'around', 'there']), ('product', ['product', 'game', 'title', 'project', 'release', 'property', 'products', 'program', 'production', 'software']), (',', ['in', 'on', 'the', 'at', '-', 'during', 'under', 'by', 'around', 'there']), (',', ['in', 'on', 'the', 'at', '-', 'during', 'under', 'by', 'around', 'there'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████▎ | 83/100 [08:07<01:39,  5.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', ['the', ',', 'of', '.', 'as', 'a', 'and', 'in', 'to', 'that']), (',', ['the', ',', 'of', '.', 'as', 'a', 'and', 'in', 'to', 'that']), ('poets', ['poets', 'writers', 'authors', 'philosophers', 'composers', 'artists', 'painters', 'poems', 'poet', 'scholars'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 84%|████████▍ | 84/100 [08:25<02:29,  9.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Polgar', ['she', 'wang', 'he', 'zhang', 'li', 'anand', 'kim', 'wu', 'zhou', 'zhao']), ('refused', ['refused', 'declined', 'refuse', 'agreed', 'refusing', 'refuses', 'refusal', 'failed', 'offered', 'continued']), ('conditions', ['conditions', 'circumstances', 'condition', 'terms', 'restrictions', 'rules', 'criteria', 'requirements', 'regulations', 'situations']), (',', [',', 'the', '.', 'of', 'to', 'and', '-', 'in', 'a', 'as']), ('forfeited', ['lost', 'surrendered', 'won', 'relinquished', 'resigned', '##feit', 'conceded', 'vacated', 'ceded', 'taken']), (',', [',', 'the', '.', 'of', 'to', 'and', '-', 'in', 'a', 'as']), ('Xie', ['jun', '.', 'jin', '##jun', 'ren', 'june', '?', ';', 'juan', 'yong']), ('Alisa', ['elena', 'irina', 'anna', 'maria', 'olga', 'alexandra', 'tatiana', 'anastasia', 'tamara', 'natalia']), ('Galliamova', ['fischer', 'nakamura', 'ivanov', 'anand', 'kim', 'wang', 'holm', '##kova', 'khan', 'adams']), ('Championship', ['championship', 'championships', 'title', 'cup', 'champion', 'tournament', 'congress', 'open', 'league', 'trophy']), (',', [',', 'the', '.', 'of', 'to', 'and', '-', 'in', 'a', 'as']), ('Xie', ['jun', '.', 'jin', '##jun', 'ren', 'june', '?', ';', 'juan', 'yong'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 85/100 [08:28<01:51,  7.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', ['were', 'was', 'charting', 'chart', 'is', 'charts', 'had', ',', 'released', 'charted']), ('hugely', ['hugely', 'highly', 'immensely', 'quite', 'very', 'wildly', 'critically', 'extremely', 'moderately', 'commercially']), (',', ['were', 'was', 'charting', 'chart', 'is', 'charts', 'had', ',', 'released', 'charted']), ('success', ['.', 'there', ';', 'elsewhere', 'here', '!', 'overseas', 'worldwide', '?', 'abroad'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|████████▌ | 86/100 [10:29<09:43, 41.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('MSN', ['some', 'one', 'most', 'many', 'part', 'several', 'all', 'another', 'few', 'other']), ('services', ['.', 'the', ')', '-', ',', \"'\", 'of', ';', 'a', ':']), ('rebranding', ['change', 'upgrade', 'merger', 'transition', 'redesign', 'changes', 'restructuring', 'move', 'acquisition', 'rebranded']), ('included', ['included', 'include', 'were', ':', 'includes', 'including', 'was', 'are', ';', ',']), ('MSN', ['some', 'one', 'most', 'many', 'part', 'several', 'all', 'another', 'few', 'other']), ('Hotmail', [';', ',', ':', 'and', '.', 'as', '(', 'the', '-', 'to']), (',', ['##n', '##ns', '##rn', '##na', '##ni', '##m', '##nl', '##g', '##on', '##ne']), ('Windows', ['the', 'a', 'his', 'other', 'her', 'all', 'those', 'fellow', 'some', 'an']), ('Hotmail', [';', ',', ':', 'and', '.', 'as', '(', 'the', '-', 'to']), (';', [',', '-', '.', ';', '(', ':', '...', 'and', 'of', 'the']), ('MSN', ['some', 'one', 'most', 'many', 'part', 'several', 'all', 'another', 'few', 'other']), ('Messenger', [';', ',', '.', ':', 'and', 'as', '(', 'the', 'turn', '##re']), (',', ['##n', '##ns', '##rn', '##na', '##ni', '##m', '##nl', '##g', '##on', '##ne']), ('Windows', ['the', 'a', 'his', 'other', 'her', 'all', 'those', 'fellow', 'some', 'an']), ('Messenger', [';', ',', '.', ':', 'and', 'as', '(', 'the', 'turn', '##re']), (';', [',', '-', '.', ';', '(', ':', '...', 'and', 'of', 'the']), ('MSN', ['some', 'one', 'most', 'many', 'part', 'several', 'all', 'another', 'few', 'other']), (',', ['##n', '##ns', '##rn', '##na', '##ni', '##m', '##nl', '##g', '##on', '##ne']), (';', [',', '-', '.', ';', '(', ':', '...', 'and', 'of', 'the']), ('MSN', ['some', 'one', 'most', 'many', 'part', 'several', 'all', 'another', 'few', 'other']), (',', ['##n', '##ns', '##rn', '##na', '##ni', '##m', '##nl', '##g', '##on', '##ne']), (';', [',', '-', '.', ';', '(', ':', '...', 'and', 'of', 'the']), ('MSN', ['some', 'one', 'most', 'many', 'part', 'several', 'all', 'another', 'few', 'other']), ('Spaces', [';', ',', '.', 'and', ':', 'as', '(', '##re', 'the', 'turn']), (',', ['##n', '##ns', '##rn', '##na', '##ni', '##m', '##nl', '##g', '##on', '##ne']), ('Windows', ['the', 'a', 'his', 'other', 'her', 'all', 'those', 'fellow', 'some', 'an']), ('Spaces', [';', ',', '.', 'and', ':', 'as', '(', '##re', 'the', 'turn']), (';', [',', '-', '.', ';', '(', ':', '...', 'and', 'of', 'the']), ('MSN', ['some', 'one', 'most', 'many', 'part', 'several', 'all', 'another', 'few', 'other']), (',', ['##n', '##ns', '##rn', '##na', '##ni', '##m', '##nl', '##g', '##on', '##ne']), ('Windows', ['the', 'a', 'his', 'other', 'her', 'all', 'those', 'fellow', 'some', 'an']), (';', [',', '-', '.', ';', '(', ':', '...', 'and', 'of', 'the']), ('MSN', ['some', 'one', 'most', 'many', 'part', 'several', 'all', 'another', 'few', 'other']), (',', ['##n', '##ns', '##rn', '##na', '##ni', '##m', '##nl', '##g', '##on', '##ne']), ('Windows', ['the', 'a', 'his', 'other', 'her', 'all', 'those', 'fellow', 'some', 'an']), ('services', ['.', 'the', ')', '-', ',', \"'\", 'of', ';', 'a', ':']), (',', ['##n', '##ns', '##rn', '##na', '##ni', '##m', '##nl', '##g', '##on', '##ne']), ('MSN', ['some', 'one', 'most', 'many', 'part', 'several', 'all', 'another', 'few', 'other']), (',', ['##n', '##ns', '##rn', '##na', '##ni', '##m', '##nl', '##g', '##on', '##ne']), ('remained', ['remained', 'remain', 'stayed', 'been', 'retained', 'remains', 'become', 'remaining', 'kept', 'continued']), ('MSN', ['some', 'one', 'most', 'many', 'part', 'several', 'all', 'another', 'few', 'other']), ('transitioning', ['transition', 'migrating', 'transitioned', 'switching', 'transitions', 'migration', 'converting', 'moving', 'conversion', 'upgrading']), ('Windows', ['the', 'a', 'his', 'other', 'her', 'all', 'those', 'fellow', 'some', 'an'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|████████▋ | 87/100 [10:30<06:22, 29.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ahrens', ['busch', 'anderson', '##zman', 'russell', 'andersen', 'warner', 'wagner', 'fuller', 'martin', 'lancaster']), (',', [',', '.', '-', ';', ':', '...', '(', 'iii', 'jr', 'and'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|████████▊ | 88/100 [10:31<04:08, 20.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', [',', '.', ';', 'again', '-', 'afterwards', 'and', 'first', 'after', 'instead'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▉ | 89/100 [10:38<03:05, 16.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('article', ['article', 'editorial', 'analysis', 'articles', 'advertisement', 'essay', 'paper', 'opinion', 'item', 'author']), ('gynaecology', ['medical', 'health', 'psychiatric', 'scientific', 'dental', 'nursing', 'psychology', 'psychological', 'pediatric', 'feminist']), ('journal', ['journal', 'magazine', 'periodical', 'journals', 'publication', 'review', 'newspaper', 'quarterly', 'newsletter', 'paper']), ('smoking', ['women', 'woman', 'men', 'females', 'mothers', 'female', 'girls', 'actresses', 'wives', 'ladies']), ('cigarettes', ['cigarettes', 'cigarette', 'tobacco', 'pipes', 'smoking', 'smoked', 'matches', 'beers', 'times', 'newspapers']), ('childless', ['childless', 'unmarried', 'pregnant', 'single', 'married', 'barren', 'widowed', 'divorced', 'sterile', 'fertile']), ('nonsmoking', ['unmarried', 'married', 'other', 'pregnant', 'single', 'heterosexual', 'older', 'childless', 'working', 'healthy'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 90/100 [10:44<02:15, 13.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('controls', ['controls', 'control', 'controllers', 'mechanics', 'restraints', 'models', 'systems', 'movements', 'controlling', 'controlled']), (',', ['activate', 'activation', 'activated', 'trigger', '##sable', 'use', 'utilize', 'surge', 'active', 'initiate']), ('Crypto', ['he', 'she', 'it', 'they', 'godzilla', 'zero', 'max', 'leo', 'neo', 'omega']), ('humans', ['humans', 'enemies', 'people', 'human', 'robots', 'animals', 'weapons', 'men', 'demons', 'targets']), (',', ['activate', 'activation', 'activated', 'trigger', '##sable', 'use', 'utilize', 'surge', 'active', 'initiate']), (',', ['activate', 'activation', 'activated', 'trigger', '##sable', 'use', 'utilize', 'surge', 'active', 'initiate']), ('activate', ['activate', 'trigger', 'activation', 'activated', 'initiate', 'use', 'utilize', 'perform', 'release', 'engage']), ('Psychokinesis', ['regeneration', 'flight', 'emotions', 'senses', 'transformation', 'powers', 'rage', 'abilities', 'it', 'power']), ('simultaneously', ['.', ';', '!', '?', '...', '|', ',', ':', '-', '।'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 91%|█████████ | 91/100 [10:46<01:31, 10.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Currently', ['currently', 'previously', 'presently', 'current', 'now', 'originally', 'generally', 'initially', '-', 'also']), ('determining', ['determining', 'determine', 'deciding', 'selecting', 'calculating', 'indicating', 'determines', 'determined', 'determination', 'decreasing']), ('precision', ['precision', 'range', 'accuracy', 'maximum', 'precise', 'rounding', 'calculation', 'proficiency', 'scope', 'vocabulary']), ('expressions', ['expressions', 'expression', 'words', 'statements', 'symbols', '##s', 'indices', 'functions', 'expresses', 'atoms'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|█████████▏| 92/100 [10:51<01:09,  8.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Terry', ['terry', 'john', 'terence', 'barry', 'gerald', 'james', 'wayne', 'christopher', 'lawrence', 'anthony']), ('Bollea', ['smith', 'williams', 'kelly', 'taylor', 'davis', 'robinson', 'anderson', 'hogan', 'allen', 'brown']), (',', ['is', 'was', 'are', 'to', 'as', 'in', 'his', 'be', 'has', 'he']), (',', ['is', 'was', 'are', 'to', 'as', 'in', 'his', 'be', 'has', 'he']), ('currently', ['currently', 'current', 'presently', 'previously', 'now', 'formerly', ',', '.', 'recently', 'is']), ('Nonstop', ['nonstop', 'recall', 'tna', 'total', '-', 'roster', 'contact', '##screen', 'on', 'direct']), ('Action', ['action', 'actions', '##nt', 'event', 'to', 'act', 'motion', 'entertainment', 'object', 'impact'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|█████████▎| 93/100 [10:59<00:58,  8.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Lesotho', ['the', ',', '.', 'of', 'as', 'a', 'and', 'in', '-', 'to']), (',', ['is', 'was', '-', 'has', 'are', ',', 'as', '(', 'in', 'exists']), ('officially', ['officially', 'formally', 'legally', 'or', 'unofficially', 'formerly', 'official', 'originally', 'currently', 'also']), ('Lesotho', ['the', ',', '.', 'of', 'as', 'a', 'and', 'in', '-', 'to']), (',', ['is', 'was', '-', 'has', 'are', ',', 'as', '(', 'in', 'exists']), ('landlocked', ['sovereign', 'separate', 'small', 'free', 'constituent', 'commonwealth', 'member', 'single', 'dependent', 'independent']), ('-', ['-', ',', 'almost', 'nearly', '##s', 'and', '.', ':', ';', '+']), ('entirely', ['entirely', 'completely', 'wholly', 'totally', 'fully', 'altogether', 'partly', 'partially', 'exclusively', 'almost']), ('surrounded', ['surrounded', 'enclosed', 'encircled', 'bordered', 'contained', 'surrounds', 'encompassed', 'surround', 'covered', 'surrounding'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████▍| 94/100 [11:03<00:41,  6.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('buildings', ['buildings', 'building', 'structures', 'facilities', 'plants', 'objects', 'property', 'houses', 'vehicles', 'infrastructure']), (',', [',', 'and', 'or', '/', 'with', ';', '.', '-', 'including', 'by']), ('equipment', ['equipment', 'machinery', 'property', 'vehicles', 'animals', 'infrastructure', 'apparatus', 'facilities', 'livestock', 'aircraft']), ('result', ['result', 'occur', 'results', 'resulted', 'consequence', 'happen', 'come', 'cause', 'resulting', 'derive']), ('short-duration', ['surface', 'severe', 'duration', 'intensity', 'destructive', 'extended', 'emergency', 'impact', 'rapid', 'prolonged']), ('deflagration', ['.', ';', 'explosion', '?', '!', 'accident', 'failure', 'landslide', 'event', 'damage'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 95/100 [11:04<00:25,  5.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', [',', ';', '.', '-', '...', ':', 'and', 'land', '(', '##s']), ('terraces', ['.', ';', '!', '|', '?', '।', 'cultivation', '...', 'irrigation', '．'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 96%|█████████▌| 96/100 [11:05<00:15,  3.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('reported', ['reported', 'recorded', 'known', 'confirmed', 'reports', 'named', 'said', 'report', 'reporting', 'expected']), ('Arlene', ['bob', 'allison', 'sandy', 'arthur', 'nancy', 'joan', 'alma', 'eric', 'diane', 'gustav'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|█████████▋| 97/100 [11:16<00:18,  6.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('perform', ['perform', 'do', 'performed', 'performance', 'fare', 'behave', 'demonstrate', 'performs', 'work', 'compete']), ('alround', ['sprint', 'junior', 'ski', 'pursuit', 'track', 'winter', 'curling', 'speed', 'relay', 'road']), ('championships', ['championships', 'championship', 'cup', 'champions', 'competitions', 'juniors', 'games', 'cups', 'awards', 'worlds']), ('Heerenveen', ['oslo', 'calgary', 'berlin', 'zagreb', 'moscow', 'trondheim', 'prague', 'sarajevo', 'boston', 'paris']), (',', ['track', 'relay', 'skate', 'single', 'cross', 'pursuit', '.', 'free', 'distance', 'skating']), (',', ['track', 'relay', 'skate', 'single', 'cross', 'pursuit', '.', 'free', 'distance', 'skating']), ('-', ['-', '/', '+', ',', 'and', '.', '&', ':', \"'\", '|']), ('Skating', ['skating', 'skater', 'hockey', 'skaters', 'skate', 'skiing', 'riding', 'racing', 'dancing', 'rink'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|█████████▊| 98/100 [11:20<00:10,  5.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Leonese', ['spanish', 'galician', 'catalan', 'basque', 'portuguese', 'french', 'romani', 'english', 'italian', 'arabic']), ('writer', ['writer', 'poet', 'author', 'painter', 'novelist', 'teacher', 'linguist', 'singer', 'journalist', 'politician']), (',', [',', 'who', ';', '.', ':', '-', 'and', 'he', '...', 'that']), ('Palacios', ['arenas', 'torre', 'santiago', 'castro', 'campos', 'medina', 'vega', 'villa', 'valle', 'alba']), ('Sil', ['sol', 'rio', 'mar', 'sur', 'leon', 'sal', 'valle', 'norte', 'rey', 'real']), ('León', ['leon', 'salamanca', 'madrid', 'monterrey', 'mora', 'spain', 'avila', 'nicaragua', 'malaga', 'zaragoza'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 99%|█████████▉| 99/100 [11:25<00:05,  5.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Grand-Rullecourt', ['ham', 'pont', 'fontaine', 'croix', 'bois', 'faux', 'bellevue', 'nes', 'champs', '##court']), ('commune', ['commune', 'communes', 'village', 'municipality', 'department', 'canton', 'town', 'hamlet', 'community', 'settlement']), ('department', ['department', 'district', 'departments', 'arrondissement', 'prefecture', 'et', 'and', 'dept', 'est', ',']), ('Nord-Pas-de-Calais', ['normandy', 'nord', 'northern', 'northwest', 'north', 'northeast', 'brittany', 'lille', 'northwestern', 'calais']), ('region', ['region', 'area', 'regional', 'district', 'department', 'zone', 'regions', 'province', 'section', 'part'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [11:27<00:00,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('reunification', ['reunification', 'unification', '1990', '1945', 'independence', '1994', '1991', '1989', 'partition', 'this']), (',', [',', ':', '-', 'of', '.', 'and', ';', '...', 'when', 'the']), ('Linden', ['linden', 'berlin', 'vienna', 'essen', 'kiel', 'brussels', 'dresden', 'royal', 'baltic', 'dusseldorf']), ('rejoined', ['rejoined', 'joined', 'rejoin', 'left', 'reopened', 'joins', 'abandoned', 'revived', 'reunited', 'returned']), ('operatic', ['operatic', 'opera', 'musical', 'artistic', 'singing', 'theatrical', 'orchestral', 'dramatic', 'concert', 'symphonic'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform operations\n",
    "X_Train = X_Train[0:100]\n",
    "Y_Train = Y_Train[0:100]\n",
    "\n",
    "simplified = []\n",
    "\n",
    "for unsimplified_text in tqdm(X_Train):\n",
    "  simplified_text=unsimplified_text\n",
    "  complexity=[textstat.difficult_words(word) for word in unsimplified_text.split()]\n",
    "  candidates_list=get_bert_candidates(unsimplified_text,complexity)\n",
    "  for diff_word, l_candidates in candidates_list:\n",
    "    candidates_order = []\n",
    "    for w in l_candidates:\n",
    "      if w.isalpha():\n",
    "        candidates_order.append((w, zipf_frequency(w, 'en')))\n",
    "    candidates_order = sorted(candidates_order, key = lambda x: x[1], reverse=True)\n",
    "    if len(candidates_order) != 0:\n",
    "      simplified_text = re.sub(diff_word,candidates_order[0][0],simplified_text)\n",
    "  simplified.append(simplified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWHiraPZhLVX"
   },
   "outputs": [],
   "source": [
    "# Perform operations\n",
    "data = {'Wiki Unsimplified Text': X_Train, 'Simplified Text': simplified}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGHg9RDG3Le9"
   },
   "source": [
    "###Simplification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "LvP59PQLriPn",
    "outputId": "3602c00f-4ae2-4a98-8215-65ad87c95be4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wiki Unsimplified Text</th>\n",
       "      <th>Simplified Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When Green tore his ACL in a preseason game , Warner took over as the Rams  tentative starter</td>\n",
       "      <td>When Green tore his ACL in a training game and Warner took over as the Rams  first starter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Royal Rumble was the twentieth annual Royal Rumble professional wrestling pay-per-view event produced by World Wrestling Entertainment</td>\n",
       "      <td>Royal Rumble was the second annual Royal Rumble professional wrestling pay-per-view event produced by World Wrestling company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Janko Prunk is a Slovenian historian of modern history</td>\n",
       "      <td>peter pop is a polish author of modern history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sometimes the balalaika is tuned `` guitar style  to G-B-D , making it easier to play for Russian guitar players , although balalaika purists frown on this tuning</td>\n",
       "      <td>Sometimes the the is tuned the on style  to G-B-D but making it easier to play for Russian on playing but although the players frown on this tuning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two days after he was sworn in as Prime Minister , the Wall Street Crash of 1929 occurred , marking the beginning of the Great Depression and subsequent Great Depression in Australia</td>\n",
       "      <td>Two days after he was sworn in as Prime Minister during the Wall Street Crash of 1929 happened during mark the beginning of the Great the and the Great the in Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Arthur is the first reported tropical storm to form in May since Tropical Storm Arlene in 1981</td>\n",
       "      <td>Arthur is the first said tropical storm to form in May since Tropical Storm bob in 1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>She did not perform so well at the World alround championships in Heerenveen , where she finished fifth , but she managed to win the 2006 - 07 Speed Skating World Cup on the 3,000 and 5,000 m track</td>\n",
       "      <td>She did not do so well at the World road games in paris free where she finished fifth free but she managed to win the 2006 and 07 Speed racing World Cup on the 3free000 and 5free000 m track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Leonese language writer , was born in Palacios del Sil in 1918 and died in León in 2007</td>\n",
       "      <td>english language author and was born in villa del real in 1918 and died in spain in 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Grand-Rullecourt is a commune in the Pas-de-Calais department in the Nord-Pas-de-Calais region of France</td>\n",
       "      <td>ham is a community in the Pas-de-Calais and in the north part of France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>After reunification , the Linden Opera rejoined the operatic world</td>\n",
       "      <td>After this the the royal Opera left the singing world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                    Wiki Unsimplified Text  \\\n",
       "0                                                                                                           When Green tore his ACL in a preseason game , Warner took over as the Rams  tentative starter    \n",
       "1                                                                  Royal Rumble was the twentieth annual Royal Rumble professional wrestling pay-per-view event produced by World Wrestling Entertainment    \n",
       "2                                                                                                                                                  Janko Prunk is a Slovenian historian of modern history    \n",
       "3                                      Sometimes the balalaika is tuned `` guitar style  to G-B-D , making it easier to play for Russian guitar players , although balalaika purists frown on this tuning    \n",
       "4                  Two days after he was sworn in as Prime Minister , the Wall Street Crash of 1929 occurred , marking the beginning of the Great Depression and subsequent Great Depression in Australia    \n",
       "..                                                                                                                                                                                                     ...   \n",
       "95                                                                                                         Arthur is the first reported tropical storm to form in May since Tropical Storm Arlene in 1981    \n",
       "96  She did not perform so well at the World alround championships in Heerenveen , where she finished fifth , but she managed to win the 2006 - 07 Speed Skating World Cup on the 3,000 and 5,000 m track    \n",
       "97                                                                                                                Leonese language writer , was born in Palacios del Sil in 1918 and died in León in 2007    \n",
       "98                                                                                               Grand-Rullecourt is a commune in the Pas-de-Calais department in the Nord-Pas-de-Calais region of France    \n",
       "99                                                                                                                                     After reunification , the Linden Opera rejoined the operatic world    \n",
       "\n",
       "                                                                                                                                                                                   Simplified Text  \n",
       "0                                                                                                      When Green tore his ACL in a training game and Warner took over as the Rams  first starter   \n",
       "1                                                                   Royal Rumble was the second annual Royal Rumble professional wrestling pay-per-view event produced by World Wrestling company   \n",
       "2                                                                                                                                                  peter pop is a polish author of modern history   \n",
       "3                                             Sometimes the the is tuned the on style  to G-B-D but making it easier to play for Russian on playing but although the players frown on this tuning   \n",
       "4                        Two days after he was sworn in as Prime Minister during the Wall Street Crash of 1929 happened during mark the beginning of the Great the and the Great the in Australia   \n",
       "..                                                                                                                                                                                             ...  \n",
       "95                                                                                                        Arthur is the first said tropical storm to form in May since Tropical Storm bob in 1981   \n",
       "96  She did not do so well at the World road games in paris free where she finished fifth free but she managed to win the 2006 and 07 Speed racing World Cup on the 3free000 and 5free000 m track   \n",
       "97                                                                                                       english language author and was born in villa del real in 1918 and died in spain in 2007   \n",
       "98                                                                                                                        ham is a community in the Pas-de-Calais and in the north part of France   \n",
       "99                                                                                                                                          After this the the royal Opera left the singing world   \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform operations\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4MfHDtwwrqrx"
   },
   "outputs": [],
   "source": [
    "# Perform operations\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
